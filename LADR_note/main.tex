\documentclass{tufte-handout}
\usepackage[english]{babel} % English language
\usepackage{amsmath,amsfonts,amsthm,amssymb}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{bm}
\usepackage{pgf,tikz}
\usepackage{float}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{enumerate,enumitem}
\usepackage{fancyhdr} % custom headers and footers
\usepackage{ragged2e}
\usepackage{sectsty} % Allow customizing section commands
% \usepackage{lmodern} % Return to CMU Serif


% ---------- Preamble ----------
\pagestyle{fancyplain} % Make all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header
\fancyfoot[L]{}
\fancyfoot[C]{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header
\allowdisplaybreaks
\geometry{
	left=13mm, % left margin
	textwidth=130mm, % main text block
	marginparsep=8mm, % gutter between main text block and margin notes
	marginparwidth=55mm % width of margin notes
}
\setlist[enumerate]{
	label=(\alph*),
	leftmargin=2.5em,
	topsep=0.5em,
	itemsep=0em,
}
\def \v {\vspace{0.2cm}}
\allsectionsfont{\normalfont\bfseries} % Make all sections centered, the default font and small caps


% ---------- Theorem Environments ----------
\theoremstyle{plain} % default
\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{props}[thm]{Propositions}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{exer}[thm]{Exercise}

\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{rems}[thm]{Remarks}


% ---------- Symbol Macros ----------
\newcommand{\bra}[1]{\mathopen{}\left(#1\right)}
\newcommand{\sbra}[1]{\mathopen{}\left[#1\right]}
\newcommand{\cbra}[1]{\mathopen{}\left\{#1\right\}}
\newcommand{\rest}[2]{\mathopen{}\left.#1\right|_{#2}}
\renewcommand{\phi}{\varphi}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\F}{\mathbb{F}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\zero}{\mathbf{0}}
\renewcommand{\intercal}{t}
% \newcommand{\U}{\bm{U}}
% \newcommand{\V}{\bm{V}}
% \newcommand{W}{\bm{W}}
% \renewcommand{\u}{\bm{u}}
% \renewcommand{\v}{\bm{v}}
% \newcommand{\w}{\bm{w}}
% \newcommand{\x}{\bm{x}}
% \newcommand{\U}{{U}}
% \newcommand{\V}{{V}}
% \newcommand{\W}{{W}}
% \renewcommand{\u}{{u}}
% \renewcommand{\v}{{v}}
% \newcommand{\w}{{w}}
% \newcommand{\x}{{x}}

\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\im}{im}
% \DeclareMathOperator{\ker}{ker} % already existed
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\rank}{rank}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\inp}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\abs}[1]{\left| #1 \right|}


% ---------- Title Section ----------
\title{	
	\normalfont\normalsize 
	{\itshape Linear Algebra Done Right} \\ [0pt]
	\huge Notes -- Linear Algebra
}
\author{Zhijie Chen}
\date{\vspace{-5pt}\normalsize\today}


\begin{document}


\justifying
\maketitle
\tableofcontents
\newpage


% \section{Prerequisites}
% We declare several notations below for convenience and clarity.
% \begin{notns}[Basic notations]
% 	\phantom{linebreak}

%     \begin{itemize}
%         \item $\F$ denotes a number field.
%         \item $U$, $V$, $W$ denotes vector spaces (usually over scalar field $\F$).
%         \item $V^S$ denotes the set of functions from a nonempty set $S$ to a vector space $V$.
%     \end{itemize}
% \end{notns}


\section{Vector Spaces}
\begin{defn}
	The complexification of $V$, denoted by $V_\C$, equals $V\times V$ with normal addition and real scalar multiplication for product space. But we write an element $(u,v)$ of $V_\C$ as $u+iv$. Complex scalar multiplication is defined by
	\[(a+bi)(u+iv)=(au-bv)+i(av+bu)\]
	for all $a,b\in\R$ and all $u,v\in V$.\footnote{Think of $V$ as a subset of $V_\C$ by identifying $u\in V$ with $u+i0$. The construction of $V_\C$ from $V$ can then be thought of as generalizing the construction of $\C^n$ from $\R^n$.}
\end{defn}

\begin{lem}[Linear dependence lemma]
	Suppose $v_1,\dots,v_m$ is a linearly dependent set in $V$. Then there exists $k\in\{1,2,\dots,m\}$ such that
	\[v_k\in\spn\cbra{v_1,\dots,v_m}.\]
	Furthermore, removing the $k^\text{th}$ term from the list does not change the span.\footnote{This lemma lays the foundation for a series of basic results for vector spaces.}
\end{lem}

\begin{thm}
	Any two bases of a finite-dimensional vector space have the same length.\footnote{This proposition ensures that \emph{dimension} is well-defined.}
\end{thm}
\begin{proof}
	Suppose $V$ is finite-dimensional. Let $\B_1$ and $\B_2$ be two bases of $V$. Considering $\B_1$ as an independent set and $\B_2$ as a spanning set leads to $\#\B_1\leq\#\B_2$. Interchanging the roles of $\B_1$ and $\B_2$ and we have $\#\B_2\leq\#\B_1$. Thus $\#\B_1=\#\B_2$.
\end{proof}


\section{Linear Maps}
\subsection{Kernal and Image of Linear Maps}
\begin{exer}
	Suppose $U$ and $V$ are finite-dimensional and $S\in\L\bra{V,W}$ and $T\in\L\bra{U,V}$. Prove that
	\[\dim\ker ST \leq \dim\ker S + \dim\ker T.\]
\end{exer}
\begin{proof}
	Restrict to $Z=\ker ST$. By the fundamental theorem of linear maps,
	\begin{align*}
		\dim Z & = \dim T(Z) + \dim\ker \rest{T}{Z} \\
		& \leq \dim T(Z) + \dim\ker T \\
		& = \dim ST(Z) + \dim\ker \rest{S}{T(Z)} + \dim\ker T \\
		& \leq \dim\ker S + \dim\ker T.\qedhere
	\end{align*}
\end{proof}

\begin{cor}[Sylvester's rank inequality]
	Suppose $A\in\F^{m,n}$ and $B\in\F^{n,p}$ are two matrices. Then\footnote{There is a slicker proof for this inequality using block matrices. But the proof here using linear maps is more informative.}
	\[\rank A+\rank B-n\leq\rank\bra{AB}.\]
\end{cor}

\subsection{Products and Quotients of Vector Spaces}
\begin{lem}\label{lem: direct sum and product space}
	Suppose $V_1,\dots,V_m$ are subspaces of $V$.\footnote{Note that $V$ does not have to be finite-dimensional. Recall that $V_1+\cdots+V_m$ is a direct sum if and only if the only way to write $0$ as a sum of $v_1+\cdots+v_m$, where each $v_k\in V_k$, is by taking each $v_k$ equal to $0$.} Define a linear map $\Gamma: V_1\times\cdots\times V_m \to V_1+\cdots+V_m$ by
	\[\Gamma\bra{v_1,\dots,v_m} = v_1+\cdots+v_m.\]
	Then $V_1+\cdots+V_m$ is a direct sum if and only if $\Gamma$ is injective.
\end{lem}

\begin{thm}
	Suppose $V$ is finite-dimensional and $V_1,\dots,V_m$ are subspaces of $V$. Then $V_1+\cdots+V_m$ is a direct sum if and only $\dim\bra{V_1+\cdots+V_m} = \dim V_1+\cdots+\dim V_m$.\footnote{Recall Lemma~\ref{lem: direct sum and product space}.}
\end{thm}
% \begin{proof}
% 	Recall Lemma~\ref{lem: direct sum and product space}.Because $\Gamma$ is surjective, by the fundamental theorem of linear maps, $V_1+\cdots+V_m$ is a direct sum if and only if $\dim\bra{V_1+\cdots+V_m} = \dim\bra{V_1\times\cdots\times V_m} = \dim V_1+\cdots+\dim V_m$.
% \end{proof}

\begin{notn}
	Suppose $T\in\L\bra{V,W}$. Define $\widetilde{T}: V+\ker V \to V$ by
	\[\widetilde{T}\bra{v+\ker T}=Tv.\]
\end{notn}

\begin{exer}
	Suppose $V_1,\dots,V_m$ are vector spaces. Prove that $\L\bra{V_1\times\cdots\times V_m,W}$ and $\L\bra{V_1,W}\times\cdots\times\L\bra{V_m,W}$ are isomorphic vector spaces. 
\end{exer}
\begin{proof}
	We construct an isomorphism $T$ between the two vector spaces.
	
	For every $\Gamma\in\L\bra{V_1\times\cdots\times V_m,W}$, define $\phi_i:V_i\to W$ for each $i\in\cbra{1,\dots,m}$ by
	\[\phi_i\bra{v_i}=\Gamma\bra{0,\dots,v_i,\dots,0}\]
	with $v_i$ in the $i^\text{th}$ slot and $0$ in all other slots. It can be verified that $\phi_i\in\L\bra{V_i,W}$.

	Let $T\bra{\Gamma}=\bra{\phi_1,\dots,\phi_m}$. It can be verified that $T$ is a linear map. We prove $T$ is an isomorphism by constructing its inverse linear map $S$.

	For every $\bra{\phi_1,\dots,\phi_m}\in\L\bra{V_1,W}\times\cdots\times\L\bra{V_m,W}$, let
	\[S\bra{\phi_1,\dots,\phi_m}\bra{v_1,\dots,v_m}=\phi_1\bra{v_1}+\cdots+\phi_m\bra{v_m}.\]
	
	It can be shown that $S$ is a linear map, and that $S\circ T=I$ and $T\circ S=I$. That proves $T$ is indeed an isomorphism between the two vector spaces.
\end{proof}

\begin{prop}\label{prop: test for translate}
	A nonempty subset $A$ of $V$ is a translate of some subspace of $V$ if and only if $\lambda v+\bra{1-\lambda}w\in A$ for all $v,w\in A$ and all $\lambda\in\F$.
\end{prop}

\begin{exer}
	Suppose $A_1=v+U_1$ and $A_2=w+U_2$ for some $v,w\in V$ and some subspaces $U_1$, $U_2$ of $V$. Prove that $A_1\cap A_2$ is either the empty set or a translate of some subspace of $V$.\footnote{Recall Proposition~\ref{prop: test for translate}.}
\end{exer}

\begin{prop}\label{prop: direct sum from quotient space}
	Suppose $U$ is a subspace of $V$ and $v_1+U,\dots,v_m+U$ is a basis of $V/U$ and $u_1,\dots,u_n$ is a basis of $U$. Then $v_1,\dots,v_m,u_1,\dots,u_n$ is a basis of $V$. In other words, $V=\spn\cbra{v_1,\dots,v_m}\oplus U$.\footnote{$V=\spn\cbra{v_1,\dots,v_m}\oplus U$ still holds without the hypothesis that $U$ is finite-dimensional.}
\end{prop}

\begin{exer}
	Suppose $U$ is a subspace of $V$ such that $V/U$ is finite-dimensional.
	\begin{enumerate}
		\item Prove that if $W$ is a finite-dimensional subspace of $V$ and $V=U+W$, then $\dim W\geq\dim V/U$.
		\item Prove that there exists a finite-dimensional subspace $W$ of $V$ such that $V=U\oplus W$ and $\dim W=\dim V/U$.
	\end{enumerate}
\end{exer}
\begin{proof}
	Let $\overline{w}_1+U,\dots,\overline{w}_m+U$ be a basis of $V/U$. Then by Proposition~\ref{prop: direct sum from quotient space}, we have $V=\spn\cbra{\overline{w}_1,\dots,\overline{w}_m}\oplus U$. Let $W_0=\spn\cbra{\overline{w}_1,\dots,\overline{w}_m}$, then $V=U\oplus W_0$, as desired.

	Now we prove that for each subspace $W$ of $V$ such that $V=U+W$, we have $\dim W\geq m=\dim V/U$.
	
	For each $\overline{w}_i\in V$ above, by definition we have $\overline{w}_i=u_i+w_i$ for some $u_i\in U$ and $w_i\in W$. It can be shown from the linear independence of $\overline{w}_1+U,\dots,\overline{w}_m+U$ that $\overline{w}_1-u_1,\dots,\overline{w}_m-u_m$ are independent vectors in $W$. Hence $\dim W\geq m$.
\end{proof}


\subsection{Duality}
\begin{thm}
	Suppose $V$ and $W$ are finite-dimensional and $T\in\L\bra{V,W}$. Then
	\begin{center}
	$T$ is surjective $\iff$ $T'$ is injective \quad and \quad $T$ is injective $\iff$ $T'$ is surjective.\footnote{This result can be useful because sometimes it is easier to verify that $T'$ is injective (surjective) than to show directly that $T$ is surjective (injective).}
	\end{center}
\end{thm}

\begin{prop}\label{prop: relation between subspace and annihilator}
	Suppose $V$ is finite-dimensional and $U$ is a subspace of $V$. Then
	\[U=\cbra{v\in V:\phi(v)=0\,\text{ for every }\,\phi\in U^0}.\]
\end{prop}

\begin{exer}
	Suppose $V$ is finite-dimensional and $U$ and $W$ are subspaces of $V$.
	\begin{enumerate}
		\item Prove that $W^0\subseteq U^0$ if and only if $U\subseteq W$.
		\item Prove that $W^0=U^0$ if and only if $U=W$.\footnote{Recall Proposition~\ref{prop: relation between subspace and annihilator}.}
	\end{enumerate}
\end{exer}

\begin{exer}
	Suppose $V$ is finite-dimensional and $U$ and $W$ are subspaces of $V$.\
	\begin{enumerate}
		\item Prove that $\bra{U+W}^0=U^0\cap W^0$.
		\item Prove that $\bra{U\cap W}^0=U^0+W^0$.
	\end{enumerate}
\end{exer}

\begin{prop}\label{prop: matrix of dual basis}
	Suppose $V$ is finite-dimensional and $v_1,\dots,v_n$ is a basis of $V$. Then $\phi_1,\dots,\phi_n\in V'$ is the dual basis of $v_1,\dots,v_n$ if and only if
	\[\begin{bmatrix}
		\M(\phi_1,(v_1,\dots,v_n))\\
		\vdots\\
		\M(\phi_n,(v_1,\dots,v_n))\\
	\end{bmatrix}=I.\]
	% where $\M\bra{\phi_i}$ is the $1\times n$ matrix of $\phi_i$ with respect to basis $v_1,\dots v_n$ of $V$ for each $i\in\cbra{1,\dots,n}$.
\end{prop}

\begin{exer}
	Suppose $V$ is finite-dimensional and $\phi_1,\dots,\phi_n$ is a basis of $V'$. Prove that there exists a basis of $V$ whose dual basis is $\phi_1,\dots,\phi_n$.
\end{exer}
\begin{proof}
	We start from an arbitrary basis $u_1,\dots,u_n$ of $V$. Let $\psi_1,\dots,\psi_n$ be its dual basis. In this proof, we take standard basis $e_1,\dots,e_n$ as the basis of $\F^n$.
	
	Define $S,T\in\L\bra{V,\F^n}$ by
	\[T(v)=\bra{\phi_1(v),\dots,\phi_n(v)},\quad S(v)=\bra{\psi_1(v),\dots,\psi_n(v)}.\]
	Then by Lemma~\ref{prop: matrix of dual basis}, $\M\bra{S,\bra{u_1,\dots,u_n}}=I$.
	
	Let $A$ be the change of basis matrix from $\psi$'s to $\phi$'s, i.e.,
	% \[A=\M\bra{I,\bra{\phi_1,\dots,\phi_n},\bra{\psi_1,\dots,\psi_n}}.\]
	\[\begin{bmatrix}\phi_1&\cdots&\phi_n\end{bmatrix}=\begin{bmatrix}\psi_1&\cdots&\psi_n\end{bmatrix}A.\]
	Then by the definition of change of basis matrix, we have
	\begin{align*}
		\M\bra{T,\bra{u_1,\dots,u_n}}&=\begin{bmatrix}
			\M\bra{\phi_1,\bra{u_1,\dots,u_n}}\\
			\vdots\\
			\M\bra{\phi_n,\bra{u_1,\dots,u_n}}\\
		\end{bmatrix}
		=A^\intercal\begin{bmatrix}
			\M\bra{\psi_1,\bra{u_1,\dots,u_n}}\\
			\vdots\\
			\M\bra{\psi_n,\bra{u_1,\dots,u_n}}\\
		\end{bmatrix}\\\\
		&=A^\intercal\cdot\M\bra{S,\bra{u_1,\dots,u_n}}=A^\intercal.
	\end{align*}

	Consider basis $v_1,\dots,v_n$ of $V$ such that the change of basis matrix from $u$'s to $v$'s is $\bra{A^\intercal}^{-1}$.\footnote{The change of basis for $V'\to V'$ corresponds to the transpose of $V\leftarrow V$, where transpose and inverse both come from duality. That gives the idea of considering $\bra{A^\intercal}^{-1}$.} Thus
	\[\M\bra{T,\bra{v_1,\dots,v_n}}=\M\bra{T,\bra{u_1,\dots,u_n}}\cdot\M\bra{I,\bra{v_1,\dots,v_n},\bra{u_1,\dots,u_n}}=I.\]
	Then by Proposition~\ref{prop: matrix of dual basis}, the dual basis of $v_1,\dots,v_n$ is precisely $\phi_1,\dots,\phi_n$, as desired.
\end{proof}


\section{Polynomials}
\begin{thm}
	Suppose $p\in\P(\F)$ is a nonconstant polynomial of degree $m$. Then $\lambda\in\F$ is a zero of $p$ if and only if there exists a polynomial $q\in\P(\F)$ of degree $m-1$ such that $p(z)=(z-\lambda)q(z)$ for every $z\in\F$.
\end{thm}

\begin{thm}
	Suppose $p\in\P(\F)$ is a nonconstant polynomial of degree $m$. Then $p$ has at most $m$ zeros in $\F$.\footnote{This theorem indicates that when a polynomial $p$ has too many zeros, $p=0$.}\footnote{This theorem implies that the coefficients of a polynomial are uniquely determined. In particular, the \emph{degree} of a polynomial is well-defined.}
\end{thm}

\begin{thm}[Division algorithm for polynomials]
	Suppose that $p,s\in\P(\F)$, with $s\neq0$. Then there exist unique polynomials $q,r\in\P(\F)$ such that $p=sq+r$.
	% \footnote{The division algorithm for polynomials can be proved without using any linear algebra. This proof makes a nice use of a basis of $\P_n(\F)$.}
\end{thm}
\begin{proof}
	Let $n=\deg p$ and $m=\deg s$. The case where $n<m$ is trivial. Thus we now assume that $n\geq m$.

	The list
	\[1,z,\dots,z^{m-1},s,zs,\dots,z^{n-m}s\]
	is linearly independent in $\P_n(\F)$. And it also has length $n+1$. Hence the list is a basis of $\P_n(\F)$.

	Because $p\in\P_n(\F)$, there exist unique constants $a_0,\dots,a_{m-1},b_0,\dots,b_{n-m}\in\F$ such that
	\begin{align*}
		p&=a_0+a_1z+\cdots+a_{m-1}z^{m-1}+b_0s+b_1zs+\cdots+b_{n-m}z^{n-m}s\\
		&=\bra{a_0+a_1z+\cdots+a_{m-1}z^{m-1}}+s\bra{b_0+b_1z+\cdots+b_{n-m}z^{n-m}}.\qedhere
	\end{align*}
\end{proof}

\begin{thm}[Fundamental theorem of algebra, first version]
	Every nonconstant polynomial with complex coefficients has a zero in $\C$.
\end{thm}
\begin{proof}
	Suppose $p\in\P(\C)$ is a nonconstant polynomial with highest-order nonzero term $c_mz^m$. Then $\abs{p(z)}\to\infty$ as $\abs{z}\to\infty$. Thus the continuous function $z\mapsto\abs{p(z)}$ has a global minimum at some $\zeta\in\C$. Assume that $p(\zeta)\neq0$.

	Consider polynomial $q=p(z+\zeta)/p(\zeta)$. The function $z\mapsto\abs{q(z)}$ has a global minimum at $z=0$. Write
	\[q(z)=1+a_kz_k+\cdots+a_mz^m\]
	where $k$ is the smallest positive integer such that the coefficient of $z_k$ is nonzero.
	
	Let $\beta$ be the $k^\text{th}$ root of $-1/a_k$. There is a constant $c>1$ such that if $t\in(0,1)$, then
	\[\abs{q(t\beta)}\leq\abs{1+a_kt^k\beta^k}+ct^{k+1}=1-t^k(1-tc).\]
	Thus taking $t$ to be $1/(2c)$ leads to $\abs{q(t\beta)}<1$. The contradiction implies that $p(\zeta)=0$, as desired.
\end{proof}

\begin{thm}[Fundamental theorem of algebra, second version]
	If $p\in\P(\C)$ is a nonconstant polynomial, then $p$ has a unique factorization of the form
	\[p(z)=c(z-\lambda_1)\cdots(z-\lambda_m),\]
	where $c,\lambda_1,\dots,\lambda_m\in\C$.
\end{thm}

\begin{thm}[Factorization of a polynomial over $\R$]
	If $p\in\P(\R)$ is a nonconstant polynomial, then $p$ has a unique factorization of the form
	\[p(x)=c(x-\lambda_1)\cdots(x-\lambda_m)(x^2+b_1x+c_1)\cdots(x^2+b_Mx+c_M),\]
	where $m,M\in\N$ and $c,\lambda_1,\dots,\lambda_m,b_1,\dots,b_M,c_1,\dots,c_M\in\R$, with $b_k^2<4c_k$ for each $k$.
\end{thm}

\begin{exer}
	Suppose $p,q\in\P(\C)$ are nonconstant polynomials with no zeros in common. Let $m=\deg p$ and $n=\deg q$. Prove that there exist $r\in\P_{n-1}(\C)$ and $s\in\P_{m-1}(\C)$ such that $rp+sq=1$.
\end{exer}
\begin{proof}
	
\end{proof}


\end{document}